{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d91e60ce",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The goal of this project is to predict car evaluations based on the characteristics provided in the car dataset in UCI Machine Learning repository. This dataset has 1728 records, each record representing a car evaluation. Each car evaluation is described with 7 attributes. 6 of the attributes represent car characteristics, such as buying price, price of the maintenance, number of doors, capacity in terms of persons to carry, the size of luggage boot, and estimated safety of the car. The seventh variable represents the evaluation of the car (unacceptable, acceptable, good, very good).\n",
    "\n",
    "We will be using 5 different classification algorithms shown below - \n",
    "\n",
    "1. K-Nearest Neighbors\n",
    "2. Decision Trees\n",
    "3. Naive Bayes\n",
    "4. Logistic Regression\n",
    "5. Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaab4c2",
   "metadata": {},
   "source": [
    "## Importing Packages\n",
    "\n",
    "We will use Sklearn, numpy and pandas to produce model results and use matplotlib for visualizations of our model results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26fe28f2",
   "metadata": {
    "id": "26fe28f2"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn import tree, linear_model, neighbors, svm\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV, KFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "Jb_rWFG2cz7b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jb_rWFG2cz7b",
    "outputId": "11cd73ab-b74b-4fe8-86b5-9bc50bd15266"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# path = \"/content/drive/MyDrive/Data/car.csv\"\n",
    "# car = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd80099",
   "metadata": {},
   "source": [
    "## Reading files and cleaning\n",
    "\n",
    "I read in the csv file and assign names to each column. I also look at some basic information about the data using the describe and info methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c50b3bc6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "c50b3bc6",
    "outputId": "36f83f5c-7682-4c6f-9783-8f8e3d1a22f0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety evaluation\n",
       "0  vhigh  vhigh     2       2    small    low      unacc\n",
       "1  vhigh  vhigh     2       2    small    med      unacc\n",
       "2  vhigh  vhigh     2       2    small   high      unacc\n",
       "3  vhigh  vhigh     2       2      med    low      unacc\n",
       "4  vhigh  vhigh     2       2      med    med      unacc"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car = pd.read_csv('car.csv', header = None)\n",
    "car.columns = ['buying','maint','doors','persons','lug_boot','safety','evaluation']\n",
    "car.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e751973",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "id": "8e751973",
    "outputId": "531c294a-e0ef-4ffe-b55f-21778dfb11da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>1210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       buying  maint doors persons lug_boot safety evaluation\n",
       "count    1728   1728  1728    1728     1728   1728       1728\n",
       "unique      4      4     4       3        3      3          4\n",
       "top     vhigh  vhigh     2       2    small    low      unacc\n",
       "freq      432    432   432     576      576    576       1210"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Looking at a summary of the columns\n",
    "car.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "143ece33",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "143ece33",
    "outputId": "e26857af-beec-4422-80c2-0f2993fb9a4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1728 entries, 0 to 1727\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   buying      1728 non-null   object\n",
      " 1   maint       1728 non-null   object\n",
      " 2   doors       1728 non-null   object\n",
      " 3   persons     1728 non-null   object\n",
      " 4   lug_boot    1728 non-null   object\n",
      " 5   safety      1728 non-null   object\n",
      " 6   evaluation  1728 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 94.6+ KB\n",
      "None\n",
      "unacc    1210\n",
      "acc       384\n",
      "good       69\n",
      "vgood      65\n",
      "Name: evaluation, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Checking for nulls\n",
    "print(car.info())\n",
    "print(car.evaluation.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde18fe2",
   "metadata": {},
   "source": [
    "## Dealing with categorical variables\n",
    "\n",
    "All the features that we have for prediction are categorical variables. My next step is to encode the variables in a numerical form using the One Hot Encoding method. Every unique value of a feature will become a new column, resulting in 21 features totally. \n",
    "\n",
    "I've also encoded the target variable into a numeric form using the following mapping - \n",
    "\n",
    "1. unacc = 0\n",
    "2. acc = 1\n",
    "3. good = 2\n",
    "4. vgood = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "196107a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "196107a7",
    "outputId": "b0e36397-8990-47f2-cea2-cdfb07fb6b6a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 1., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 1.],\n",
       "       [0., 1., 0., ..., 1., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating one-hot encoding for the categorical variables\n",
    "X = car.iloc[:,0:6]\n",
    "y = np.where(car['evaluation'] == 'unacc',0,\n",
    "             np.where(car['evaluation'] == 'acc',\n",
    "                      1,np.where(car['evaluation'] == 'good',2,3)))\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "X_one_hot = encoder.fit_transform(X)\n",
    "X_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad40b865",
   "metadata": {},
   "source": [
    "## Split into train, test and validation\n",
    "\n",
    "To avoid overfitting, we will split our data into 2 parts - train and test. \n",
    "\n",
    "We will use the validation set to select the best model from all the different hyperparameters and then finally compare the results of all 3 different models on the testing dataset to decide which model works the best.\n",
    "\n",
    "The split that I have chosen - \n",
    "\n",
    "- Train = 70% \n",
    "- Test = 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75112d72",
   "metadata": {
    "id": "75112d72"
   },
   "outputs": [],
   "source": [
    "# Split into training, validation and testing set\n",
    "#Train, test, validation split\n",
    "random.seed(456)\n",
    "\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X_one_hot,y, \n",
    "                                                  train_size=0.7, \n",
    "                                                  stratify = y)\n",
    "\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, \n",
    "                                                    train_size=0.5, \n",
    "                                                    stratify = y_rem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b466e9b3",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "We will use nested cross-validation to select the best model out of the 5 choices we have - KNN, Decision Tree, Logistic Regression, Naive Bayes and Support Vector Machine.\n",
    "\n",
    "We follow the steps below for each model - \n",
    "\n",
    "1. We select the list of parameters we want to optimize over for each model and put it into a dictionary \n",
    "2. Set up the inner cross-validation object by using this parameter grid\n",
    "3. Set up the outer cross-validation object.\n",
    "5. Create a grid search object using the inner cv object. This will be used to find the best parameter for each outer fold.\n",
    "4. Get the cross validation score using the grid search object as the estimator and the outer_cv as the cross validation parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "656b6318",
   "metadata": {
    "id": "656b6318"
   },
   "outputs": [],
   "source": [
    "### Create model objects\n",
    "\n",
    "knn = make_pipeline(MinMaxScaler(), \n",
    "                    neighbors.KNeighborsClassifier(metric = 'hamming'))\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "logit = make_pipeline(MinMaxScaler(), \n",
    "                      linear_model.LogisticRegression(max_iter = 10000, solver = 'saga'))\n",
    "svm_classifier = make_pipeline(MinMaxScaler(), svm.SVC())\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "\n",
    "###### Create Parameter List\n",
    "\n",
    "## KNN\n",
    "k_range = list(range(1,10))\n",
    "knn_params = dict(kneighborsclassifier__n_neighbors = k_range, \n",
    "                  kneighborsclassifier__weights = ['uniform','distance'], \n",
    "                  kneighborsclassifier__p = [1,2,3])\n",
    "\n",
    "## Decision Tree\n",
    "depth_range = list(range(1,10))\n",
    "min_samples_range = list(range(2,10))\n",
    "impurity_decrease_range = list(np.linspace(0.1,0.5,5))\n",
    "\n",
    "dt_params = dict(criterion = ['gini','entropy'], \n",
    "                 splitter = ['best','random'],\n",
    "                 max_depth = depth_range, \n",
    "                 max_features = ['auto','sqrt','log2',None], #\n",
    "                 random_state = [456],\n",
    "                 min_impurity_decrease = impurity_decrease_range,\n",
    "                 class_weight = ['balanced',None])\n",
    "\n",
    "## Logistic Regression\n",
    "\n",
    "c_range = [0.1, 1, 10]\n",
    "l1r_range = [0,0.5,1]\n",
    "\n",
    "logit_params = dict(logisticregression__penalty = ['elasticnet'],\n",
    "                    logisticregression__random_state = [456],\n",
    "                    logisticregression__C = c_range,\n",
    "                    logisticregression__class_weight = ['balanced', None],\n",
    "                    logisticregression__l1_ratio = l1r_range)\n",
    "\n",
    "## Support Vector Machine\n",
    "\n",
    "svm_params = {\"svc__C\": c_range,\n",
    "              \"svc__gamma\": [0.1, 1, 10],\n",
    "              \"svc__degree\": list(range(1,5)),\n",
    "              \"svc__kernel\": ['rbf'],\n",
    "              \"svc__class_weight\" : ['balanced',None],\n",
    "              \"svc__decision_function_shape\" : ['ovo','ovr'],\n",
    "              \"svc__break_ties\" : [False],\n",
    "              \"svc__random_state\" : [456]\n",
    "            }\n",
    "\n",
    "## Naive Bayes\n",
    "\n",
    "nb_params = dict(alpha = list(np.linspace(0,1,11)),fit_prior = [True,False])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f34866fb",
   "metadata": {
    "id": "f34866fb"
   },
   "outputs": [],
   "source": [
    "##### Set up inner and outerCV loops\n",
    "\n",
    "inner_cv = KFold(n_splits = 5, shuffle = True, random_state = 456)\n",
    "outer_cv = KFold(n_splits = 5, shuffle = True, random_state = 456)\n",
    "\n",
    "### Use metric\n",
    "\n",
    "scoring = 'f1_weighted'\n",
    "\n",
    "\n",
    "### Create Grid Search estimators\n",
    "\n",
    "knn_gs = GridSearchCV(estimator = knn, param_grid = knn_params, \n",
    "                      scoring = scoring, cv = inner_cv)\n",
    "dt_gs = GridSearchCV(estimator = dt, param_grid = dt_params, \n",
    "                     scoring = scoring, cv = inner_cv)\n",
    "logit_gs = GridSearchCV(estimator = logit, param_grid = logit_params, \n",
    "                        scoring = scoring, cv = inner_cv)\n",
    "svm_gs = GridSearchCV(estimator = svm_classifier, param_grid = svm_params, \n",
    "                      scoring = scoring, cv = inner_cv)\n",
    "nb_gs = GridSearchCV(estimator = nb_classifier, param_grid = nb_params, \n",
    "                     scoring = scoring, cv = inner_cv)\n",
    "\n",
    "### performing Nested cross validation using the inner and outer loops\n",
    "dt_score = cross_val_score(estimator = dt_gs, X = X_train, y = y_train, \n",
    "                           cv = outer_cv, scoring = scoring)\n",
    "knn_score = cross_val_score(estimator = knn_gs, X = X_train, y = y_train, \n",
    "                            cv = outer_cv, scoring = scoring)\n",
    "logit_score = cross_val_score(estimator = logit_gs, X = X_train, y = y_train, \n",
    "                              cv = outer_cv, scoring = scoring)\n",
    "svm_score = cross_val_score(estimator = svm_gs, X = X_train, y = y_train, \n",
    "                            cv = outer_cv, scoring = scoring)\n",
    "nb_score = cross_val_score(estimator = nb_gs, X = X_train, y = y_train, \n",
    "                           cv = outer_cv, scoring = scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d91bee2",
   "metadata": {
    "id": "6d91bee2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn = 0.88 ± 0.01\n",
      "dt = 0.77 ± 0.02\n",
      "logit = 0.93 ± 0.01\n",
      "svm = 0.99 ± 0.01\n",
      "nb = 0.83 ± 0.01\n"
     ]
    }
   ],
   "source": [
    "print(\"knn = \" + str(np.round(knn_score.mean(),2)) + \" \" + u\"\\u00B1\" + \" \" \n",
    "      + str(np.round(knn_score.std(),2)))\n",
    "print(\"dt = \" + str(np.round(dt_score.mean(),2)) + \" \" + u\"\\u00B1\" + \" \" \n",
    "      + str(np.round(dt_score.std(),2)))\n",
    "print(\"logit = \" + str(np.round(logit_score.mean(),2)) + \" \" + u\"\\u00B1\" + \" \"\n",
    "      + str(np.round(logit_score.std(),2)))\n",
    "print(\"svm = \" + str(np.round(svm_score.mean(),2)) + \" \" + u\"\\u00B1\" + \" \"\n",
    "      + str(np.round(svm_score.std(),2)))\n",
    "print(\"nb = \" + str(np.round(nb_score.mean(),2)) + \" \" + u\"\\u00B1\" + \" \"\n",
    "      + str(np.round(nb_score.std(),2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda2e714",
   "metadata": {},
   "source": [
    "## Best model\n",
    "\n",
    "It looks like the Support Vector Machine does the best in terms of the f1-score. We will use the Support Vector Machine to create our final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "mTflpgr3ujyB",
   "metadata": {
    "id": "mTflpgr3ujyB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97530421, 0.99580341, 1.        , 0.99195894, 0.98065177])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55f2981",
   "metadata": {},
   "source": [
    "## Re-training and evaluation\n",
    "\n",
    "Now we re-train our SVM model on the entire training dataset and evaluate it on the testing set. \n",
    "\n",
    "Looking at the classification report below, here are some observations - \n",
    "\n",
    "1. The overall accuracy and f1-score is 0.99, which shows that our model performs generalizes well on the testing dataset.\n",
    "2. In most classes, the model performs well. The 'good' class does not perform as well as other classes with an f1-score of 0.95 and a recall of 0.91.\n",
    "3. Overall, the model does a fairly good job of predicting car evaluations decently well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "xEIn3APymx9f",
   "metadata": {
    "id": "xEIn3APymx9f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       180\n",
      "           1       1.00      0.98      0.99        59\n",
      "           2       1.00      0.91      0.95        11\n",
      "           3       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           0.99       260\n",
      "   macro avg       1.00      0.97      0.98       260\n",
      "weighted avg       0.99      0.99      0.99       260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Looks like SVM performs the best\n",
    "\n",
    "## Using SVM to train our data \n",
    "clf_svm = svm_gs.fit(X_train, y_train)\n",
    "\n",
    "#Predict on test data\n",
    "y_pred = clf_svm.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515205c3",
   "metadata": {},
   "source": [
    "## Treating the data as numeric\n",
    "\n",
    "What if we hadn't coded the data using OneHotEncoder and treated the variables as numeric variables instead. We code this in manually.\n",
    "\n",
    "Once that is done, we will repeat the steps of nested cross validation for model selection and then re-train our best model to evaluate on the test data and compare which type of model is the best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ddff64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a label encoding for the categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = car.iloc[:,0:6]\n",
    "y = np.where(car['evaluation'] == 'unacc',0,np.where(car['evaluation'] == 'acc',1,np.where(car['evaluation'] == 'good',2,3)))\n",
    "\n",
    "\n",
    "# https://sparkbyexamples.com/pandas/pandas-remap-values-in-column-with-a-dictionary-dict/#:~:text=Using%20Pandas%20DataFrame.-,replace(),regular%20expressions%20for%20regex%20substitutions.\n",
    "\n",
    "X['buying'].replace({'vhigh':3, 'high':2, 'med':1, 'low':0}, inplace=True)\n",
    "X['maint'].replace({'vhigh':3, 'high':2, 'med':1, 'low':0}, inplace=True)\n",
    "X['doors'].replace({'5more':3,'4':2, '3':1, '2':0}, inplace=True)\n",
    "X['persons'].replace({'more':2, '4':1, '2':0}, inplace=True)\n",
    "X['lug_boot'].replace({'big':2, 'med':1, 'small':0}, inplace=True)\n",
    "X['safety'].replace({'high':2, 'med':1, 'low':0}, inplace=True)\n",
    "X.head()\n",
    "\n",
    "## Split into train and test_Sets\n",
    "\n",
    "# Split into training, validation and testing set\n",
    "#Train, test, validation split\n",
    "random.seed(456)\n",
    "\n",
    "X_train_l, X_rem_l, y_train_l, y_rem_l = train_test_split(X_label,y, train_size=0.7, stratify = y)\n",
    "\n",
    "X_valid_l, X_test_l, y_valid_l, y_test_l = train_test_split(X_rem_l,y_rem_l, train_size=0.5, stratify = y_rem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11c9774a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      buying  maint  doors  persons  lug_boot  safety\n",
       "33         3      3      1        0         0       1\n",
       "1221       2      1      1        0         0       1\n",
       "850        0      1      3        1         1       2\n",
       "1672       1      1      1        2         0       2\n",
       "1470       1      0      2        1         1       1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_l.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3b4fc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn = 0.88 ± 0.02\n",
      "dt = 0.77 ± 0.02\n",
      "logit = 0.64 ± 0.04\n",
      "svm = 0.96 ± 0.02\n",
      "nb = 0.59 ± 0.02\n"
     ]
    }
   ],
   "source": [
    "### Create model objects\n",
    "\n",
    "knn = make_pipeline(MinMaxScaler(), neighbors.KNeighborsClassifier())\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "logit = make_pipeline(MinMaxScaler(), linear_model.LogisticRegression(max_iter = 10000, solver = 'saga'))\n",
    "svm_classifier = make_pipeline(MinMaxScaler(), svm.SVC())\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "##### Set up inner and outerCV loops\n",
    "\n",
    "inner_cv = KFold(n_splits = 5, shuffle = True, random_state = 456)\n",
    "outer_cv = KFold(n_splits = 5, shuffle = True, random_state = 456)\n",
    "\n",
    "### Use metric\n",
    "\n",
    "scoring = 'f1_weighted'\n",
    "\n",
    "\n",
    "### Create Grid Search estimators\n",
    "\n",
    "knn_gs = GridSearchCV(estimator = knn, param_grid = knn_params, \n",
    "                      scoring = scoring, cv = inner_cv)\n",
    "dt_gs = GridSearchCV(estimator = dt, param_grid = dt_params, \n",
    "                     scoring = scoring, cv = inner_cv)\n",
    "logit_gs = GridSearchCV(estimator = logit, param_grid = logit_params, \n",
    "                        scoring = scoring, cv = inner_cv)\n",
    "svm_gs = GridSearchCV(estimator = svm_classifier, param_grid = svm_params, \n",
    "                      scoring = scoring, cv = inner_cv)\n",
    "nb_gs = GridSearchCV(estimator = nb_classifier, param_grid = nb_params, \n",
    "                     scoring = scoring, cv = inner_cv)\n",
    "\n",
    "### performing Nested cross validation using the inner and outer loops\n",
    "dt_score = cross_val_score(estimator = dt_gs, X = X_train_l, y = y_train_l, \n",
    "                           cv = outer_cv, scoring = scoring)\n",
    "knn_score = cross_val_score(estimator = knn_gs, X = X_train_l, y = y_train_l, \n",
    "                            cv = outer_cv, scoring = scoring)\n",
    "logit_score = cross_val_score(estimator = logit_gs, X = X_train_l, y = y_train_l, \n",
    "                              cv = outer_cv, scoring = scoring)\n",
    "svm_score = cross_val_score(estimator = svm_gs, X = X_train_l, y = y_train_l, \n",
    "                            cv = outer_cv, scoring = scoring)\n",
    "nb_score = cross_val_score(estimator = nb_gs, X = X_train_l, y = y_train_l, \n",
    "                           cv = outer_cv, scoring = scoring)\n",
    "\n",
    "print(\"knn = \" + str(np.round(knn_score.mean(),2)) + \" \" + u\"\\u00B1\" + \" \" \n",
    "      + str(np.round(knn_score.std(),2)))\n",
    "print(\"dt = \" + str(np.round(dt_score.mean(),2)) + \" \" + u\"\\u00B1\" + \" \" \n",
    "      + str(np.round(dt_score.std(),2)))\n",
    "print(\"logit = \" + str(np.round(logit_score.mean(),2)) + \" \" + u\"\\u00B1\" + \" \"\n",
    "      + str(np.round(logit_score.std(),2)))\n",
    "print(\"svm = \" + str(np.round(svm_score.mean(),2)) + \" \" + u\"\\u00B1\" + \" \"\n",
    "      + str(np.round(svm_score.std(),2)))\n",
    "print(\"nb = \" + str(np.round(nb_score.mean(),2)) + \" \" + u\"\\u00B1\" + \" \"\n",
    "      + str(np.round(nb_score.std(),2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9819db74",
   "metadata": {},
   "source": [
    "## Retraining and evaluating on the test set\n",
    "\n",
    "The model that does the best is still the SVM. However, it seems like the overall model accuracies have taken a hit.\n",
    "\n",
    "\n",
    "Let's retrain the model on the testing set to see the test accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d36244e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71       183\n",
      "           1       0.26      0.26      0.26        57\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.10      0.09      0.10        11\n",
      "\n",
      "    accuracy                           0.56       260\n",
      "   macro avg       0.27      0.27      0.27       260\n",
      "weighted avg       0.56      0.56      0.56       260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Looks like SVM performs the best\n",
    "\n",
    "## Using SVM to train our data \n",
    "clf_svm_l = svm_gs.fit(X_train_l, y_train_l)\n",
    "\n",
    "#Predict on test data\n",
    "y_pred = clf_svm_l.predict(X_test_l)\n",
    "\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96aa9f67",
   "metadata": {},
   "source": [
    "## Conclusions and comparisons with oneHot transformation\n",
    "\n",
    "Looking at the results above, it look like SVM is still the best model using this kind of transformation. However, the model accuracies/f1-scores have taken a hit. \n",
    "\n",
    "The new model has a very low weighted f-1 score of 0.56 vs the onehot model of 0.99. Using a one-hot encoding is definitely better than using a regular numeric coding in this particular case. Some of the more general pros and cons of using this numerical coding are listed below -\n",
    "\n",
    "Pros - \n",
    "1. The number of features are much less. This will improve the model training process by being more computationally efficient. \n",
    "2. If the data has an inherent order, it might be more useful to use and the difference between each level is the same, we can use a numerical encoding method.\n",
    "\n",
    "Cons - \n",
    "1. If the data is of nominal type, it does not make sense to encode it in a numerical format. This is because the difference between each level might not be the same and the model will estimate its paramenters assuming that the data is interval level.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW 4- Q5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
